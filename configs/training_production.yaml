# Production Training Configuration
# Run with: zenml pipeline run src.pipelines.training.training_pipeline --config configs/training_production.yaml
#
# Production settings: full model, strict thresholds, robust preprocessing

# Pipeline parameters (maps directly to training_pipeline() arguments)
parameters:
  test_size: 0.2
  n_estimators: 100          # Full ensemble size
  max_depth: 10              # Full depth
  min_accuracy: 0.80         # Strict threshold for production
  enable_resampling: true    # Enable SMOTE for imbalanced data
  imbalance_threshold: 0.3   # Trigger SMOTE if minority < 30%
  enable_pca: false          # Disable PCA unless needed
  max_features_for_pca: 50
  pca_components: 30

# Pipeline-level settings
settings:
  # Docker configuration (uses platform-managed settings)
  docker:
    parent_image: python:3.11-slim
    python_package_installer: uv
    required_integrations:
      - mlflow
      - sklearn
    apt_packages:
      - git
      - curl
      - ca-certificates
    environment:
      PYTHONUNBUFFERED: "1"
      PYTHONDONTWRITEBYTECODE: "1"

  # Resource configuration for orchestrators
  resources:
    cpu_count: 4
    memory: 8GB

# Step-specific overrides
steps:
  train_model:
    settings:
      resources:
        cpu_count: 4
        memory: 8GB

  validate_model_performance:
    parameters:
      min_accuracy: 0.80
      min_precision: 0.80
      min_recall: 0.80
